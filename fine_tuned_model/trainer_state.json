{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9804455580369301,
  "eval_steps": 500,
  "global_step": 18000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005446919766871834,
      "grad_norm": 10.648293495178223,
      "learning_rate": 4.974671823084046e-05,
      "loss": 1.9643,
      "step": 100
    },
    {
      "epoch": 0.010893839533743668,
      "grad_norm": 10.129409790039062,
      "learning_rate": 4.947437224249687e-05,
      "loss": 1.225,
      "step": 200
    },
    {
      "epoch": 0.0163407593006155,
      "grad_norm": 4.662313461303711,
      "learning_rate": 4.920202625415328e-05,
      "loss": 1.3069,
      "step": 300
    },
    {
      "epoch": 0.021787679067487336,
      "grad_norm": 5.978466987609863,
      "learning_rate": 4.8929680265809685e-05,
      "loss": 1.4933,
      "step": 400
    },
    {
      "epoch": 0.02723459883435917,
      "grad_norm": 4.9337867125132107e-08,
      "learning_rate": 4.865733427746609e-05,
      "loss": 1.2146,
      "step": 500
    },
    {
      "epoch": 0.02723459883435917,
      "eval_loss": 1.3712021112442017,
      "eval_runtime": 224.5333,
      "eval_samples_per_second": 16.746,
      "eval_steps_per_second": 8.373,
      "step": 500
    },
    {
      "epoch": 0.032681518601231,
      "grad_norm": 1.0147898197174072,
      "learning_rate": 4.83849882891225e-05,
      "loss": 1.3559,
      "step": 600
    },
    {
      "epoch": 0.03812843836810284,
      "grad_norm": 0.9567961096763611,
      "learning_rate": 4.811264230077891e-05,
      "loss": 1.2761,
      "step": 700
    },
    {
      "epoch": 0.04357535813497467,
      "grad_norm": 0.525010883808136,
      "learning_rate": 4.784029631243532e-05,
      "loss": 1.5658,
      "step": 800
    },
    {
      "epoch": 0.0490222779018465,
      "grad_norm": 3.8484811782836914,
      "learning_rate": 4.7567950324091725e-05,
      "loss": 1.3049,
      "step": 900
    },
    {
      "epoch": 0.05446919766871834,
      "grad_norm": 3.3893909454345703,
      "learning_rate": 4.729560433574814e-05,
      "loss": 1.4021,
      "step": 1000
    },
    {
      "epoch": 0.05446919766871834,
      "eval_loss": 1.350754737854004,
      "eval_runtime": 225.2651,
      "eval_samples_per_second": 16.691,
      "eval_steps_per_second": 8.346,
      "step": 1000
    },
    {
      "epoch": 0.05991611743559017,
      "grad_norm": 0.6727285981178284,
      "learning_rate": 4.7023258347404545e-05,
      "loss": 1.5004,
      "step": 1100
    },
    {
      "epoch": 0.065363037202462,
      "grad_norm": 2.6537113189697266,
      "learning_rate": 4.675091235906096e-05,
      "loss": 1.3676,
      "step": 1200
    },
    {
      "epoch": 0.07080995696933384,
      "grad_norm": 3.0948867797851562,
      "learning_rate": 4.6478566370717366e-05,
      "loss": 1.5486,
      "step": 1300
    },
    {
      "epoch": 0.07625687673620568,
      "grad_norm": 4.846965789794922,
      "learning_rate": 4.620622038237377e-05,
      "loss": 1.2205,
      "step": 1400
    },
    {
      "epoch": 0.0817037965030775,
      "grad_norm": 6.099817752838135,
      "learning_rate": 4.593387439403018e-05,
      "loss": 1.4307,
      "step": 1500
    },
    {
      "epoch": 0.0817037965030775,
      "eval_loss": 1.340488314628601,
      "eval_runtime": 226.2011,
      "eval_samples_per_second": 16.622,
      "eval_steps_per_second": 8.311,
      "step": 1500
    },
    {
      "epoch": 0.08715071626994934,
      "grad_norm": 4.085049152374268,
      "learning_rate": 4.5661528405686586e-05,
      "loss": 1.3777,
      "step": 1600
    },
    {
      "epoch": 0.09259763603682118,
      "grad_norm": 4.093409538269043,
      "learning_rate": 4.5389182417343e-05,
      "loss": 1.2,
      "step": 1700
    },
    {
      "epoch": 0.098044555803693,
      "grad_norm": 4.560837268829346,
      "learning_rate": 4.5116836428999406e-05,
      "loss": 1.3496,
      "step": 1800
    },
    {
      "epoch": 0.10349147557056484,
      "grad_norm": 2.288576126098633,
      "learning_rate": 4.484449044065581e-05,
      "loss": 1.1843,
      "step": 1900
    },
    {
      "epoch": 0.10893839533743668,
      "grad_norm": 0.15645365417003632,
      "learning_rate": 4.457214445231222e-05,
      "loss": 1.3754,
      "step": 2000
    },
    {
      "epoch": 0.10893839533743668,
      "eval_loss": 1.3374561071395874,
      "eval_runtime": 226.6033,
      "eval_samples_per_second": 16.593,
      "eval_steps_per_second": 8.296,
      "step": 2000
    },
    {
      "epoch": 0.11438531510430851,
      "grad_norm": 0.0,
      "learning_rate": 4.4299798463968626e-05,
      "loss": 1.3012,
      "step": 2100
    },
    {
      "epoch": 0.11983223487118035,
      "grad_norm": 0.30821216106414795,
      "learning_rate": 4.402745247562504e-05,
      "loss": 1.327,
      "step": 2200
    },
    {
      "epoch": 0.12527915463805217,
      "grad_norm": 2.9977757930755615,
      "learning_rate": 4.3755106487281446e-05,
      "loss": 1.4975,
      "step": 2300
    },
    {
      "epoch": 0.130726074404924,
      "grad_norm": 3.074887275695801,
      "learning_rate": 4.348276049893785e-05,
      "loss": 1.2538,
      "step": 2400
    },
    {
      "epoch": 0.13617299417179585,
      "grad_norm": 3.091229882556945e-05,
      "learning_rate": 4.321041451059426e-05,
      "loss": 1.334,
      "step": 2500
    },
    {
      "epoch": 0.13617299417179585,
      "eval_loss": 1.3339108228683472,
      "eval_runtime": 225.8357,
      "eval_samples_per_second": 16.649,
      "eval_steps_per_second": 8.325,
      "step": 2500
    },
    {
      "epoch": 0.14161991393866769,
      "grad_norm": 3.440608263015747,
      "learning_rate": 4.2938068522250666e-05,
      "loss": 1.4635,
      "step": 2600
    },
    {
      "epoch": 0.14706683370553952,
      "grad_norm": 3.652982473373413,
      "learning_rate": 4.266572253390708e-05,
      "loss": 1.5222,
      "step": 2700
    },
    {
      "epoch": 0.15251375347241136,
      "grad_norm": 2.9553399085998535,
      "learning_rate": 4.239337654556349e-05,
      "loss": 1.5931,
      "step": 2800
    },
    {
      "epoch": 0.15796067323928317,
      "grad_norm": 2.6751978397369385,
      "learning_rate": 4.212103055721989e-05,
      "loss": 1.3988,
      "step": 2900
    },
    {
      "epoch": 0.163407593006155,
      "grad_norm": 0.0005275005823932588,
      "learning_rate": 4.18486845688763e-05,
      "loss": 1.2179,
      "step": 3000
    },
    {
      "epoch": 0.163407593006155,
      "eval_loss": 1.3298159837722778,
      "eval_runtime": 226.4646,
      "eval_samples_per_second": 16.603,
      "eval_steps_per_second": 8.302,
      "step": 3000
    },
    {
      "epoch": 0.16885451277302685,
      "grad_norm": 3.725581645965576,
      "learning_rate": 4.157633858053271e-05,
      "loss": 1.3297,
      "step": 3100
    },
    {
      "epoch": 0.1743014325398987,
      "grad_norm": 2.1246187686920166,
      "learning_rate": 4.130399259218912e-05,
      "loss": 1.3473,
      "step": 3200
    },
    {
      "epoch": 0.17974835230677053,
      "grad_norm": 1.0995343923568726,
      "learning_rate": 4.103164660384553e-05,
      "loss": 1.32,
      "step": 3300
    },
    {
      "epoch": 0.18519527207364236,
      "grad_norm": 0.0,
      "learning_rate": 4.0759300615501934e-05,
      "loss": 1.2437,
      "step": 3400
    },
    {
      "epoch": 0.1906421918405142,
      "grad_norm": 0.0,
      "learning_rate": 4.048695462715835e-05,
      "loss": 1.2955,
      "step": 3500
    },
    {
      "epoch": 0.1906421918405142,
      "eval_loss": 1.3285479545593262,
      "eval_runtime": 658.2433,
      "eval_samples_per_second": 5.712,
      "eval_steps_per_second": 2.856,
      "step": 3500
    },
    {
      "epoch": 0.196089111607386,
      "grad_norm": 3.5056498050689697,
      "learning_rate": 4.0214608638814754e-05,
      "loss": 1.3874,
      "step": 3600
    },
    {
      "epoch": 0.20153603137425785,
      "grad_norm": 4.705516815185547,
      "learning_rate": 3.994226265047116e-05,
      "loss": 1.4248,
      "step": 3700
    },
    {
      "epoch": 0.2069829511411297,
      "grad_norm": 0.2958899140357971,
      "learning_rate": 3.9669916662127574e-05,
      "loss": 1.212,
      "step": 3800
    },
    {
      "epoch": 0.21242987090800153,
      "grad_norm": 3.4048073291778564,
      "learning_rate": 3.939757067378398e-05,
      "loss": 1.168,
      "step": 3900
    },
    {
      "epoch": 0.21787679067487337,
      "grad_norm": 2.759159803390503,
      "learning_rate": 3.912522468544039e-05,
      "loss": 1.1804,
      "step": 4000
    },
    {
      "epoch": 0.21787679067487337,
      "eval_loss": 1.3235468864440918,
      "eval_runtime": 226.6848,
      "eval_samples_per_second": 16.587,
      "eval_steps_per_second": 8.293,
      "step": 4000
    },
    {
      "epoch": 0.2233237104417452,
      "grad_norm": 3.8399834632873535,
      "learning_rate": 3.8852878697096794e-05,
      "loss": 1.2617,
      "step": 4100
    },
    {
      "epoch": 0.22877063020861702,
      "grad_norm": 1.914289116859436,
      "learning_rate": 3.85805327087532e-05,
      "loss": 1.3546,
      "step": 4200
    },
    {
      "epoch": 0.23421754997548885,
      "grad_norm": 2.6326780319213867,
      "learning_rate": 3.8308186720409614e-05,
      "loss": 1.0575,
      "step": 4300
    },
    {
      "epoch": 0.2396644697423607,
      "grad_norm": 3.3956637382507324,
      "learning_rate": 3.803584073206602e-05,
      "loss": 1.2041,
      "step": 4400
    },
    {
      "epoch": 0.24511138950923253,
      "grad_norm": 3.1180286407470703,
      "learning_rate": 3.776349474372243e-05,
      "loss": 1.314,
      "step": 4500
    },
    {
      "epoch": 0.24511138950923253,
      "eval_loss": 1.3238638639450073,
      "eval_runtime": 225.6282,
      "eval_samples_per_second": 16.665,
      "eval_steps_per_second": 8.332,
      "step": 4500
    },
    {
      "epoch": 0.25055830927610434,
      "grad_norm": 0.0,
      "learning_rate": 3.7491148755378835e-05,
      "loss": 1.3847,
      "step": 4600
    },
    {
      "epoch": 0.2560052290429762,
      "grad_norm": 2.559971570968628,
      "learning_rate": 3.721880276703524e-05,
      "loss": 1.4296,
      "step": 4700
    },
    {
      "epoch": 0.261452148809848,
      "grad_norm": 0.3148508071899414,
      "learning_rate": 3.6946456778691655e-05,
      "loss": 1.4111,
      "step": 4800
    },
    {
      "epoch": 0.26689906857671986,
      "grad_norm": 3.8076095581054688,
      "learning_rate": 3.667411079034806e-05,
      "loss": 1.2164,
      "step": 4900
    },
    {
      "epoch": 0.2723459883435917,
      "grad_norm": 0.5161517262458801,
      "learning_rate": 3.640176480200447e-05,
      "loss": 1.2051,
      "step": 5000
    },
    {
      "epoch": 0.2723459883435917,
      "eval_loss": 1.322047233581543,
      "eval_runtime": 226.0094,
      "eval_samples_per_second": 16.636,
      "eval_steps_per_second": 8.318,
      "step": 5000
    },
    {
      "epoch": 0.27779290811046353,
      "grad_norm": 3.8467700481414795,
      "learning_rate": 3.6129418813660875e-05,
      "loss": 1.4957,
      "step": 5100
    },
    {
      "epoch": 0.28323982787733537,
      "grad_norm": 3.5449745655059814,
      "learning_rate": 3.585707282531728e-05,
      "loss": 1.4125,
      "step": 5200
    },
    {
      "epoch": 0.2886867476442072,
      "grad_norm": 0.0,
      "learning_rate": 3.5584726836973695e-05,
      "loss": 1.1068,
      "step": 5300
    },
    {
      "epoch": 0.29413366741107905,
      "grad_norm": 2.341919422149658,
      "learning_rate": 3.53123808486301e-05,
      "loss": 1.3722,
      "step": 5400
    },
    {
      "epoch": 0.2995805871779509,
      "grad_norm": 2.254080057144165,
      "learning_rate": 3.504003486028651e-05,
      "loss": 1.1949,
      "step": 5500
    },
    {
      "epoch": 0.2995805871779509,
      "eval_loss": 1.3212254047393799,
      "eval_runtime": 224.9208,
      "eval_samples_per_second": 16.717,
      "eval_steps_per_second": 8.358,
      "step": 5500
    },
    {
      "epoch": 0.3050275069448227,
      "grad_norm": 3.203173875808716,
      "learning_rate": 3.4767688871942915e-05,
      "loss": 1.2925,
      "step": 5600
    },
    {
      "epoch": 0.31047442671169456,
      "grad_norm": 1.2664390802383423,
      "learning_rate": 3.449534288359932e-05,
      "loss": 1.3961,
      "step": 5700
    },
    {
      "epoch": 0.31592134647856634,
      "grad_norm": 4.07442045211792,
      "learning_rate": 3.4222996895255736e-05,
      "loss": 1.2135,
      "step": 5800
    },
    {
      "epoch": 0.3213682662454382,
      "grad_norm": 3.91607403755188,
      "learning_rate": 3.395065090691214e-05,
      "loss": 1.2559,
      "step": 5900
    },
    {
      "epoch": 0.32681518601231,
      "grad_norm": 2.4834139347076416,
      "learning_rate": 3.367830491856855e-05,
      "loss": 0.9323,
      "step": 6000
    },
    {
      "epoch": 0.32681518601231,
      "eval_loss": 1.3214225769042969,
      "eval_runtime": 227.2737,
      "eval_samples_per_second": 16.544,
      "eval_steps_per_second": 8.272,
      "step": 6000
    },
    {
      "epoch": 0.33226210577918186,
      "grad_norm": 0.0,
      "learning_rate": 3.340595893022496e-05,
      "loss": 1.2031,
      "step": 6100
    },
    {
      "epoch": 0.3377090255460537,
      "grad_norm": 1.995375394821167,
      "learning_rate": 3.313361294188137e-05,
      "loss": 1.4075,
      "step": 6200
    },
    {
      "epoch": 0.34315594531292554,
      "grad_norm": 0.0,
      "learning_rate": 3.2861266953537776e-05,
      "loss": 1.2764,
      "step": 6300
    },
    {
      "epoch": 0.3486028650797974,
      "grad_norm": 3.1693832874298096,
      "learning_rate": 3.258892096519419e-05,
      "loss": 1.1301,
      "step": 6400
    },
    {
      "epoch": 0.3540497848466692,
      "grad_norm": 2.670691728591919,
      "learning_rate": 3.2316574976850596e-05,
      "loss": 1.4111,
      "step": 6500
    },
    {
      "epoch": 0.3540497848466692,
      "eval_loss": 1.3158366680145264,
      "eval_runtime": 227.2662,
      "eval_samples_per_second": 16.544,
      "eval_steps_per_second": 8.272,
      "step": 6500
    },
    {
      "epoch": 0.35949670461354105,
      "grad_norm": 4.552350997924805,
      "learning_rate": 3.2044228988507e-05,
      "loss": 1.1781,
      "step": 6600
    },
    {
      "epoch": 0.3649436243804129,
      "grad_norm": 3.4690418243408203,
      "learning_rate": 3.177188300016341e-05,
      "loss": 1.6274,
      "step": 6700
    },
    {
      "epoch": 0.37039054414728473,
      "grad_norm": 2.7530367374420166,
      "learning_rate": 3.1499537011819816e-05,
      "loss": 1.3619,
      "step": 6800
    },
    {
      "epoch": 0.37583746391415657,
      "grad_norm": 1.8822078704833984,
      "learning_rate": 3.122719102347623e-05,
      "loss": 1.1599,
      "step": 6900
    },
    {
      "epoch": 0.3812843836810284,
      "grad_norm": 0.0,
      "learning_rate": 3.0954845035132637e-05,
      "loss": 1.1988,
      "step": 7000
    },
    {
      "epoch": 0.3812843836810284,
      "eval_loss": 1.3148959875106812,
      "eval_runtime": 225.705,
      "eval_samples_per_second": 16.659,
      "eval_steps_per_second": 8.329,
      "step": 7000
    },
    {
      "epoch": 0.3867313034479002,
      "grad_norm": 4.315917491912842,
      "learning_rate": 3.068249904678904e-05,
      "loss": 1.3635,
      "step": 7100
    },
    {
      "epoch": 0.392178223214772,
      "grad_norm": 2.633498430252075,
      "learning_rate": 3.041015305844545e-05,
      "loss": 1.3962,
      "step": 7200
    },
    {
      "epoch": 0.39762514298164386,
      "grad_norm": 0.0,
      "learning_rate": 3.013780707010186e-05,
      "loss": 1.2943,
      "step": 7300
    },
    {
      "epoch": 0.4030720627485157,
      "grad_norm": 0.39337393641471863,
      "learning_rate": 2.9865461081758267e-05,
      "loss": 1.1861,
      "step": 7400
    },
    {
      "epoch": 0.40851898251538754,
      "grad_norm": 1.057265043258667,
      "learning_rate": 2.9593115093414674e-05,
      "loss": 1.1903,
      "step": 7500
    },
    {
      "epoch": 0.40851898251538754,
      "eval_loss": 1.3122867345809937,
      "eval_runtime": 227.3563,
      "eval_samples_per_second": 16.538,
      "eval_steps_per_second": 8.269,
      "step": 7500
    },
    {
      "epoch": 0.4139659022822594,
      "grad_norm": 0.4356183111667633,
      "learning_rate": 2.9320769105071084e-05,
      "loss": 1.3293,
      "step": 7600
    },
    {
      "epoch": 0.4194128220491312,
      "grad_norm": 1.4419809579849243,
      "learning_rate": 2.904842311672749e-05,
      "loss": 1.2479,
      "step": 7700
    },
    {
      "epoch": 0.42485974181600306,
      "grad_norm": 3.679445743560791,
      "learning_rate": 2.87760771283839e-05,
      "loss": 1.3763,
      "step": 7800
    },
    {
      "epoch": 0.4303066615828749,
      "grad_norm": 3.189621686935425,
      "learning_rate": 2.8503731140040307e-05,
      "loss": 1.4205,
      "step": 7900
    },
    {
      "epoch": 0.43575358134974673,
      "grad_norm": 0.752674400806427,
      "learning_rate": 2.8231385151696714e-05,
      "loss": 1.4336,
      "step": 8000
    },
    {
      "epoch": 0.43575358134974673,
      "eval_loss": 1.3127965927124023,
      "eval_runtime": 227.2486,
      "eval_samples_per_second": 16.546,
      "eval_steps_per_second": 8.273,
      "step": 8000
    },
    {
      "epoch": 0.44120050111661857,
      "grad_norm": 0.18256083130836487,
      "learning_rate": 2.7959039163353124e-05,
      "loss": 1.2494,
      "step": 8100
    },
    {
      "epoch": 0.4466474208834904,
      "grad_norm": 1.20363450050354,
      "learning_rate": 2.768669317500953e-05,
      "loss": 1.3886,
      "step": 8200
    },
    {
      "epoch": 0.45209434065036225,
      "grad_norm": 3.8743741512298584,
      "learning_rate": 2.741434718666594e-05,
      "loss": 1.2161,
      "step": 8300
    },
    {
      "epoch": 0.45754126041723403,
      "grad_norm": 2.7599987983703613,
      "learning_rate": 2.7142001198322348e-05,
      "loss": 1.0947,
      "step": 8400
    },
    {
      "epoch": 0.46298818018410587,
      "grad_norm": 2.9142885208129883,
      "learning_rate": 2.6869655209978754e-05,
      "loss": 1.3799,
      "step": 8500
    },
    {
      "epoch": 0.46298818018410587,
      "eval_loss": 1.3100765943527222,
      "eval_runtime": 227.2612,
      "eval_samples_per_second": 16.545,
      "eval_steps_per_second": 8.272,
      "step": 8500
    },
    {
      "epoch": 0.4684350999509777,
      "grad_norm": 2.3829503059387207,
      "learning_rate": 2.6597309221635168e-05,
      "loss": 1.2631,
      "step": 8600
    },
    {
      "epoch": 0.47388201971784955,
      "grad_norm": 2.6770195960998535,
      "learning_rate": 2.6324963233291578e-05,
      "loss": 1.2122,
      "step": 8700
    },
    {
      "epoch": 0.4793289394847214,
      "grad_norm": 0.0,
      "learning_rate": 2.6052617244947985e-05,
      "loss": 1.37,
      "step": 8800
    },
    {
      "epoch": 0.4847758592515932,
      "grad_norm": 4.359966278076172,
      "learning_rate": 2.5780271256604395e-05,
      "loss": 1.2095,
      "step": 8900
    },
    {
      "epoch": 0.49022277901846506,
      "grad_norm": 1.3193069696426392,
      "learning_rate": 2.55079252682608e-05,
      "loss": 1.3779,
      "step": 9000
    },
    {
      "epoch": 0.49022277901846506,
      "eval_loss": 1.3081382513046265,
      "eval_runtime": 226.2127,
      "eval_samples_per_second": 16.622,
      "eval_steps_per_second": 8.311,
      "step": 9000
    },
    {
      "epoch": 0.4956696987853369,
      "grad_norm": 0.4710926115512848,
      "learning_rate": 2.5235579279917208e-05,
      "loss": 1.314,
      "step": 9100
    },
    {
      "epoch": 0.5011166185522087,
      "grad_norm": 3.821335554122925,
      "learning_rate": 2.4963233291573615e-05,
      "loss": 1.4276,
      "step": 9200
    },
    {
      "epoch": 0.5065635383190805,
      "grad_norm": 0.0,
      "learning_rate": 2.4690887303230025e-05,
      "loss": 1.1973,
      "step": 9300
    },
    {
      "epoch": 0.5120104580859524,
      "grad_norm": 2.6568706035614014,
      "learning_rate": 2.4418541314886435e-05,
      "loss": 1.3946,
      "step": 9400
    },
    {
      "epoch": 0.5174573778528242,
      "grad_norm": 0.6316418647766113,
      "learning_rate": 2.4146195326542842e-05,
      "loss": 1.2917,
      "step": 9500
    },
    {
      "epoch": 0.5174573778528242,
      "eval_loss": 1.3061764240264893,
      "eval_runtime": 225.6208,
      "eval_samples_per_second": 16.665,
      "eval_steps_per_second": 8.333,
      "step": 9500
    },
    {
      "epoch": 0.522904297619696,
      "grad_norm": 2.5874218940734863,
      "learning_rate": 2.387384933819925e-05,
      "loss": 1.0142,
      "step": 9600
    },
    {
      "epoch": 0.5283512173865679,
      "grad_norm": 2.8567986488342285,
      "learning_rate": 2.360150334985566e-05,
      "loss": 1.3028,
      "step": 9700
    },
    {
      "epoch": 0.5337981371534397,
      "grad_norm": 0.0,
      "learning_rate": 2.3329157361512065e-05,
      "loss": 1.1858,
      "step": 9800
    },
    {
      "epoch": 0.5392450569203115,
      "grad_norm": 2.3489725589752197,
      "learning_rate": 2.3056811373168475e-05,
      "loss": 1.4514,
      "step": 9900
    },
    {
      "epoch": 0.5446919766871834,
      "grad_norm": 3.232776403427124,
      "learning_rate": 2.2784465384824882e-05,
      "loss": 1.2125,
      "step": 10000
    },
    {
      "epoch": 0.5446919766871834,
      "eval_loss": 1.3068495988845825,
      "eval_runtime": 225.0014,
      "eval_samples_per_second": 16.711,
      "eval_steps_per_second": 8.356,
      "step": 10000
    },
    {
      "epoch": 0.5501388964540552,
      "grad_norm": 2.6882472038269043,
      "learning_rate": 2.251211939648129e-05,
      "loss": 1.0723,
      "step": 10100
    },
    {
      "epoch": 0.5555858162209271,
      "grad_norm": 3.1139538288116455,
      "learning_rate": 2.22397734081377e-05,
      "loss": 1.134,
      "step": 10200
    },
    {
      "epoch": 0.5610327359877989,
      "grad_norm": 2.5775272846221924,
      "learning_rate": 2.1967427419794106e-05,
      "loss": 1.3508,
      "step": 10300
    },
    {
      "epoch": 0.5664796557546707,
      "grad_norm": 4.059370173337129e-09,
      "learning_rate": 2.1695081431450516e-05,
      "loss": 1.2388,
      "step": 10400
    },
    {
      "epoch": 0.5719265755215426,
      "grad_norm": 0.3944300413131714,
      "learning_rate": 2.1422735443106922e-05,
      "loss": 1.4634,
      "step": 10500
    },
    {
      "epoch": 0.5719265755215426,
      "eval_loss": 1.304332971572876,
      "eval_runtime": 225.6902,
      "eval_samples_per_second": 16.66,
      "eval_steps_per_second": 8.33,
      "step": 10500
    },
    {
      "epoch": 0.5773734952884144,
      "grad_norm": 2.56107234954834,
      "learning_rate": 2.1150389454763333e-05,
      "loss": 1.1299,
      "step": 10600
    },
    {
      "epoch": 0.5828204150552863,
      "grad_norm": 0.20493024587631226,
      "learning_rate": 2.0878043466419743e-05,
      "loss": 1.1676,
      "step": 10700
    },
    {
      "epoch": 0.5882673348221581,
      "grad_norm": 3.985654592514038,
      "learning_rate": 2.060569747807615e-05,
      "loss": 1.4351,
      "step": 10800
    },
    {
      "epoch": 0.5937142545890299,
      "grad_norm": 0.9069714546203613,
      "learning_rate": 2.0333351489732556e-05,
      "loss": 1.1831,
      "step": 10900
    },
    {
      "epoch": 0.5991611743559018,
      "grad_norm": 2.6011054515838623,
      "learning_rate": 2.0061005501388966e-05,
      "loss": 1.0838,
      "step": 11000
    },
    {
      "epoch": 0.5991611743559018,
      "eval_loss": 1.3033154010772705,
      "eval_runtime": 226.9598,
      "eval_samples_per_second": 16.567,
      "eval_steps_per_second": 8.283,
      "step": 11000
    },
    {
      "epoch": 0.6046080941227736,
      "grad_norm": 4.4179810920752516e-09,
      "learning_rate": 1.9788659513045373e-05,
      "loss": 1.3551,
      "step": 11100
    },
    {
      "epoch": 0.6100550138896454,
      "grad_norm": 2.669250726699829,
      "learning_rate": 1.9516313524701783e-05,
      "loss": 1.2523,
      "step": 11200
    },
    {
      "epoch": 0.6155019336565173,
      "grad_norm": 3.5981438159942627,
      "learning_rate": 1.924396753635819e-05,
      "loss": 1.3813,
      "step": 11300
    },
    {
      "epoch": 0.6209488534233891,
      "grad_norm": 2.5231401920318604,
      "learning_rate": 1.8971621548014596e-05,
      "loss": 1.0812,
      "step": 11400
    },
    {
      "epoch": 0.626395773190261,
      "grad_norm": 2.1784172243854982e-09,
      "learning_rate": 1.8699275559671007e-05,
      "loss": 1.1905,
      "step": 11500
    },
    {
      "epoch": 0.626395773190261,
      "eval_loss": 1.3024585247039795,
      "eval_runtime": 226.5611,
      "eval_samples_per_second": 16.596,
      "eval_steps_per_second": 8.298,
      "step": 11500
    },
    {
      "epoch": 0.6318426929571327,
      "grad_norm": 2.4744815826416016,
      "learning_rate": 1.8426929571327413e-05,
      "loss": 1.2085,
      "step": 11600
    },
    {
      "epoch": 0.6372896127240045,
      "grad_norm": 2.254080057144165,
      "learning_rate": 1.8154583582983823e-05,
      "loss": 1.1628,
      "step": 11700
    },
    {
      "epoch": 0.6427365324908764,
      "grad_norm": 3.40701961517334,
      "learning_rate": 1.7882237594640234e-05,
      "loss": 1.0935,
      "step": 11800
    },
    {
      "epoch": 0.6481834522577482,
      "grad_norm": 2.7052230834960938,
      "learning_rate": 1.760989160629664e-05,
      "loss": 1.354,
      "step": 11900
    },
    {
      "epoch": 0.65363037202462,
      "grad_norm": 2.456681728363037,
      "learning_rate": 1.733754561795305e-05,
      "loss": 1.2793,
      "step": 12000
    },
    {
      "epoch": 0.65363037202462,
      "eval_loss": 1.3013195991516113,
      "eval_runtime": 316.0215,
      "eval_samples_per_second": 11.898,
      "eval_steps_per_second": 5.949,
      "step": 12000
    },
    {
      "epoch": 0.6590772917914919,
      "grad_norm": 0.43174993991851807,
      "learning_rate": 1.7065199629609457e-05,
      "loss": 1.2946,
      "step": 12100
    },
    {
      "epoch": 0.6645242115583637,
      "grad_norm": 3.3555720424516267e-09,
      "learning_rate": 1.6792853641265864e-05,
      "loss": 1.2616,
      "step": 12200
    },
    {
      "epoch": 0.6699711313252356,
      "grad_norm": 3.5007917881011963,
      "learning_rate": 1.6520507652922274e-05,
      "loss": 1.4227,
      "step": 12300
    },
    {
      "epoch": 0.6754180510921074,
      "grad_norm": 3.008209705352783,
      "learning_rate": 1.624816166457868e-05,
      "loss": 1.2783,
      "step": 12400
    },
    {
      "epoch": 0.6808649708589792,
      "grad_norm": 2.5062575340270996,
      "learning_rate": 1.597581567623509e-05,
      "loss": 1.2277,
      "step": 12500
    },
    {
      "epoch": 0.6808649708589792,
      "eval_loss": 1.2999792098999023,
      "eval_runtime": 226.1353,
      "eval_samples_per_second": 16.627,
      "eval_steps_per_second": 8.314,
      "step": 12500
    },
    {
      "epoch": 0.6863118906258511,
      "grad_norm": 2.0158746242523193,
      "learning_rate": 1.5703469687891497e-05,
      "loss": 1.3133,
      "step": 12600
    },
    {
      "epoch": 0.6917588103927229,
      "grad_norm": 3.9260401725769043,
      "learning_rate": 1.5433847159431343e-05,
      "loss": 1.3356,
      "step": 12700
    },
    {
      "epoch": 0.6972057301595947,
      "grad_norm": 0.20861788094043732,
      "learning_rate": 1.516150117108775e-05,
      "loss": 1.2599,
      "step": 12800
    },
    {
      "epoch": 0.7026526499264666,
      "grad_norm": 2.9349129793132533e-09,
      "learning_rate": 1.4889155182744158e-05,
      "loss": 1.4366,
      "step": 12900
    },
    {
      "epoch": 0.7080995696933384,
      "grad_norm": 0.2852337956428528,
      "learning_rate": 1.4616809194400567e-05,
      "loss": 1.3183,
      "step": 13000
    },
    {
      "epoch": 0.7080995696933384,
      "eval_loss": 1.2985118627548218,
      "eval_runtime": 223.3264,
      "eval_samples_per_second": 16.836,
      "eval_steps_per_second": 8.418,
      "step": 13000
    },
    {
      "epoch": 0.7135464894602103,
      "grad_norm": 2.4146502017974854,
      "learning_rate": 1.4344463206056977e-05,
      "loss": 1.14,
      "step": 13100
    },
    {
      "epoch": 0.7189934092270821,
      "grad_norm": 3.718614101409912,
      "learning_rate": 1.4072117217713385e-05,
      "loss": 1.2478,
      "step": 13200
    },
    {
      "epoch": 0.7244403289939539,
      "grad_norm": 3.5148913860321045,
      "learning_rate": 1.3799771229369794e-05,
      "loss": 1.4022,
      "step": 13300
    },
    {
      "epoch": 0.7298872487608258,
      "grad_norm": 2.1530449390411377,
      "learning_rate": 1.35274252410262e-05,
      "loss": 1.3875,
      "step": 13400
    },
    {
      "epoch": 0.7353341685276976,
      "grad_norm": 2.586778163909912,
      "learning_rate": 1.3255079252682609e-05,
      "loss": 1.339,
      "step": 13500
    },
    {
      "epoch": 0.7353341685276976,
      "eval_loss": 1.2979239225387573,
      "eval_runtime": 3585.7965,
      "eval_samples_per_second": 1.049,
      "eval_steps_per_second": 0.524,
      "step": 13500
    },
    {
      "epoch": 0.7407810882945695,
      "grad_norm": 3.199702262878418,
      "learning_rate": 1.2982733264339017e-05,
      "loss": 1.2177,
      "step": 13600
    },
    {
      "epoch": 0.7462280080614413,
      "grad_norm": 2.4262921810150146,
      "learning_rate": 1.2710387275995425e-05,
      "loss": 1.3714,
      "step": 13700
    },
    {
      "epoch": 0.7516749278283131,
      "grad_norm": 3.781076431274414,
      "learning_rate": 1.2438041287651834e-05,
      "loss": 1.4069,
      "step": 13800
    },
    {
      "epoch": 0.757121847595185,
      "grad_norm": 2.814021110534668,
      "learning_rate": 1.216569529930824e-05,
      "loss": 1.3032,
      "step": 13900
    },
    {
      "epoch": 0.7625687673620568,
      "grad_norm": 1.5539320707321167,
      "learning_rate": 1.189334931096465e-05,
      "loss": 1.2789,
      "step": 14000
    },
    {
      "epoch": 0.7625687673620568,
      "eval_loss": 1.296555757522583,
      "eval_runtime": 225.2302,
      "eval_samples_per_second": 16.694,
      "eval_steps_per_second": 8.347,
      "step": 14000
    },
    {
      "epoch": 0.7680156871289285,
      "grad_norm": 1.9855085611343384,
      "learning_rate": 1.1621003322621059e-05,
      "loss": 1.1841,
      "step": 14100
    },
    {
      "epoch": 0.7734626068958004,
      "grad_norm": 3.324023723602295,
      "learning_rate": 1.1348657334277468e-05,
      "loss": 1.2438,
      "step": 14200
    },
    {
      "epoch": 0.7789095266626722,
      "grad_norm": 0.3937075734138489,
      "learning_rate": 1.1076311345933874e-05,
      "loss": 1.1883,
      "step": 14300
    },
    {
      "epoch": 0.784356446429544,
      "grad_norm": 2.794454574584961,
      "learning_rate": 1.0803965357590283e-05,
      "loss": 1.3502,
      "step": 14400
    },
    {
      "epoch": 0.7898033661964159,
      "grad_norm": 0.48243457078933716,
      "learning_rate": 1.0531619369246691e-05,
      "loss": 1.1938,
      "step": 14500
    },
    {
      "epoch": 0.7898033661964159,
      "eval_loss": 1.2961467504501343,
      "eval_runtime": 224.0992,
      "eval_samples_per_second": 16.778,
      "eval_steps_per_second": 8.389,
      "step": 14500
    },
    {
      "epoch": 0.7952502859632877,
      "grad_norm": 2.853532314300537,
      "learning_rate": 1.02592733809031e-05,
      "loss": 1.1217,
      "step": 14600
    },
    {
      "epoch": 0.8006972057301596,
      "grad_norm": 3.193610668182373,
      "learning_rate": 9.986927392559508e-06,
      "loss": 1.4761,
      "step": 14700
    },
    {
      "epoch": 0.8061441254970314,
      "grad_norm": 0.0,
      "learning_rate": 9.714581404215916e-06,
      "loss": 1.2419,
      "step": 14800
    },
    {
      "epoch": 0.8115910452639032,
      "grad_norm": 3.31112003326416,
      "learning_rate": 9.442235415872325e-06,
      "loss": 1.2087,
      "step": 14900
    },
    {
      "epoch": 0.8170379650307751,
      "grad_norm": 3.808609962463379,
      "learning_rate": 9.169889427528733e-06,
      "loss": 1.3074,
      "step": 15000
    },
    {
      "epoch": 0.8170379650307751,
      "eval_loss": 1.29427969455719,
      "eval_runtime": 224.1169,
      "eval_samples_per_second": 16.777,
      "eval_steps_per_second": 8.388,
      "step": 15000
    },
    {
      "epoch": 0.8224848847976469,
      "grad_norm": 1.3176064406206223e-10,
      "learning_rate": 8.897543439185142e-06,
      "loss": 1.1334,
      "step": 15100
    },
    {
      "epoch": 0.8279318045645188,
      "grad_norm": 2.5454025268554688,
      "learning_rate": 8.625197450841548e-06,
      "loss": 1.2283,
      "step": 15200
    },
    {
      "epoch": 0.8333787243313906,
      "grad_norm": 1.1204254627227783,
      "learning_rate": 8.352851462497958e-06,
      "loss": 1.3214,
      "step": 15300
    },
    {
      "epoch": 0.8388256440982624,
      "grad_norm": 0.872289776802063,
      "learning_rate": 8.080505474154367e-06,
      "loss": 1.1116,
      "step": 15400
    },
    {
      "epoch": 0.8442725638651343,
      "grad_norm": 2.7223973274230957,
      "learning_rate": 7.808159485810775e-06,
      "loss": 1.3471,
      "step": 15500
    },
    {
      "epoch": 0.8442725638651343,
      "eval_loss": 1.2940250635147095,
      "eval_runtime": 225.6401,
      "eval_samples_per_second": 16.664,
      "eval_steps_per_second": 8.332,
      "step": 15500
    },
    {
      "epoch": 0.8497194836320061,
      "grad_norm": 3.5815908908843994,
      "learning_rate": 7.535813497467183e-06,
      "loss": 1.2825,
      "step": 15600
    },
    {
      "epoch": 0.855166403398878,
      "grad_norm": 1.5953360795974731,
      "learning_rate": 7.26346750912359e-06,
      "loss": 1.3634,
      "step": 15700
    },
    {
      "epoch": 0.8606133231657498,
      "grad_norm": 4.533703327178955,
      "learning_rate": 6.991121520779999e-06,
      "loss": 1.1869,
      "step": 15800
    },
    {
      "epoch": 0.8660602429326216,
      "grad_norm": 2.036201000213623,
      "learning_rate": 6.718775532436408e-06,
      "loss": 1.1038,
      "step": 15900
    },
    {
      "epoch": 0.8715071626994935,
      "grad_norm": 3.09397554397583,
      "learning_rate": 6.4464295440928164e-06,
      "loss": 1.3638,
      "step": 16000
    },
    {
      "epoch": 0.8715071626994935,
      "eval_loss": 1.2921466827392578,
      "eval_runtime": 227.3586,
      "eval_samples_per_second": 16.538,
      "eval_steps_per_second": 8.269,
      "step": 16000
    },
    {
      "epoch": 0.8769540824663653,
      "grad_norm": 1.49057280407483e-10,
      "learning_rate": 6.174083555749224e-06,
      "loss": 1.0958,
      "step": 16100
    },
    {
      "epoch": 0.8824010022332371,
      "grad_norm": 1.8231796026229858,
      "learning_rate": 5.901737567405632e-06,
      "loss": 1.2068,
      "step": 16200
    },
    {
      "epoch": 0.887847922000109,
      "grad_norm": 2.3165295124053955,
      "learning_rate": 5.629391579062041e-06,
      "loss": 1.3771,
      "step": 16300
    },
    {
      "epoch": 0.8932948417669808,
      "grad_norm": 0.0,
      "learning_rate": 5.357045590718449e-06,
      "loss": 1.287,
      "step": 16400
    },
    {
      "epoch": 0.8987417615338527,
      "grad_norm": 2.6569249629974365,
      "learning_rate": 5.084699602374858e-06,
      "loss": 1.2627,
      "step": 16500
    },
    {
      "epoch": 0.8987417615338527,
      "eval_loss": 1.2919270992279053,
      "eval_runtime": 225.7139,
      "eval_samples_per_second": 16.658,
      "eval_steps_per_second": 8.329,
      "step": 16500
    },
    {
      "epoch": 0.9041886813007245,
      "grad_norm": 2.570028781890869,
      "learning_rate": 4.812353614031265e-06,
      "loss": 1.3709,
      "step": 16600
    },
    {
      "epoch": 0.9096356010675962,
      "grad_norm": 0.5587248802185059,
      "learning_rate": 4.54273108557111e-06,
      "loss": 1.1924,
      "step": 16700
    },
    {
      "epoch": 0.9150825208344681,
      "grad_norm": 0.0004375243734102696,
      "learning_rate": 4.270385097227518e-06,
      "loss": 1.205,
      "step": 16800
    },
    {
      "epoch": 0.9205294406013399,
      "grad_norm": 0.28944531083106995,
      "learning_rate": 3.998039108883926e-06,
      "loss": 1.2856,
      "step": 16900
    },
    {
      "epoch": 0.9259763603682117,
      "grad_norm": 0.9104728102684021,
      "learning_rate": 3.725693120540335e-06,
      "loss": 1.2292,
      "step": 17000
    },
    {
      "epoch": 0.9259763603682117,
      "eval_loss": 1.2911444902420044,
      "eval_runtime": 225.4198,
      "eval_samples_per_second": 16.68,
      "eval_steps_per_second": 8.34,
      "step": 17000
    },
    {
      "epoch": 0.9314232801350836,
      "grad_norm": 0.7938519716262817,
      "learning_rate": 3.453347132196743e-06,
      "loss": 1.4202,
      "step": 17100
    },
    {
      "epoch": 0.9368701999019554,
      "grad_norm": 0.46904420852661133,
      "learning_rate": 3.181001143853151e-06,
      "loss": 1.4587,
      "step": 17200
    },
    {
      "epoch": 0.9423171196688273,
      "grad_norm": 3.274683952331543,
      "learning_rate": 2.9086551555095596e-06,
      "loss": 1.3308,
      "step": 17300
    },
    {
      "epoch": 0.9477640394356991,
      "grad_norm": 2.510338306427002,
      "learning_rate": 2.636309167165968e-06,
      "loss": 1.3424,
      "step": 17400
    },
    {
      "epoch": 0.9532109592025709,
      "grad_norm": 2.440591335296631,
      "learning_rate": 2.363963178822376e-06,
      "loss": 1.1298,
      "step": 17500
    },
    {
      "epoch": 0.9532109592025709,
      "eval_loss": 1.2910797595977783,
      "eval_runtime": 225.806,
      "eval_samples_per_second": 16.651,
      "eval_steps_per_second": 8.326,
      "step": 17500
    },
    {
      "epoch": 0.9586578789694428,
      "grad_norm": 2.0739805698394775,
      "learning_rate": 2.0916171904787844e-06,
      "loss": 1.1704,
      "step": 17600
    },
    {
      "epoch": 0.9641047987363146,
      "grad_norm": 0.0,
      "learning_rate": 1.8192712021351928e-06,
      "loss": 1.2105,
      "step": 17700
    },
    {
      "epoch": 0.9695517185031864,
      "grad_norm": 3.193085618136138e-08,
      "learning_rate": 1.5469252137916008e-06,
      "loss": 1.2981,
      "step": 17800
    },
    {
      "epoch": 0.9749986382700583,
      "grad_norm": 3.728750228881836,
      "learning_rate": 1.2745792254480092e-06,
      "loss": 1.2024,
      "step": 17900
    },
    {
      "epoch": 0.9804455580369301,
      "grad_norm": 1.8559128046035767,
      "learning_rate": 1.0022332371044174e-06,
      "loss": 1.2351,
      "step": 18000
    },
    {
      "epoch": 0.9804455580369301,
      "eval_loss": 1.2902532815933228,
      "eval_runtime": 226.8143,
      "eval_samples_per_second": 16.577,
      "eval_steps_per_second": 8.289,
      "step": 18000
    }
  ],
  "logging_steps": 100,
  "max_steps": 18359,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2351628288000000.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
